{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8122ff68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math as math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82e74435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(n):\n",
    "    '''\n",
    "    returns data of n random points around centers (1,1) and (-1,-1) each\n",
    "    points aroung (1,1): label 1\n",
    "    points aroung (-1,-1): label 0\n",
    "    '''\n",
    "    \n",
    "    c1 = np.random.normal(1, 0.5, (50, 2))\n",
    "    c1 = np.hstack((c1, np.ones((50,1))))\n",
    "\n",
    "    c2 = np.random.normal(-1, 0.5, (50, 2))\n",
    "    c2 = np.hstack((c2, np.zeros((50,1))))\n",
    "\n",
    "    data = np.vstack((c1, c2))\n",
    "    return data\n",
    "\n",
    "def sig_act(s):\n",
    "    return 1.0/(1.0+math.exp(-s))\n",
    "\n",
    "def sig_act_prime(s):\n",
    "    return math.exp(-s)/(1.0+math.exp(-s))**2\n",
    "\n",
    "def p_classifier(x1,x2,theta):\n",
    "# compute 2-layer planar perceptron classifier for given inputs x1, x2\n",
    "# parameter theta: a nine component vector\n",
    "\n",
    "# change to weight, bias notation\n",
    "    w11 = theta[0]; w12 = theta[1]; w21 = theta[2]; w22 =theta[3]\n",
    "    w31 = theta[4]; w32 = theta[5]; b1 = theta[6]; b2=theta[7]; b3=theta[8]\n",
    "\n",
    "    u1 = w11*x1 + w12*x2 + b1\n",
    "    u2 = w21*x1 + w22*x2 + b2\n",
    "      \n",
    "    z1 = sig_act(u1)            # hidden node outputs\n",
    "    z2 = sig_act(u2)\n",
    "    u3 = w31*z1 + w32*z2 +b3    # 2nd layer\n",
    "        \n",
    "    \n",
    "    out = sig_act(u3)         # output\n",
    "\n",
    "    return(out)\n",
    "\n",
    "def Loss(data, theta):\n",
    "    '''returns Loss for provided separation line'''\n",
    "    \n",
    "    #calculate class prediction with specified line c_hat = sig(y - kx -d)\n",
    "    loss = 0\n",
    "    for i in range(len(data)):\n",
    "        c_hat = p_classifier(data[i,0], data[i,1] ,theta)\n",
    "        loss += (data[i,2] - c_hat)**2\n",
    "\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4dc974c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = create_data(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81f154ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_walk_metropolis_hastings(data, ntot, proposal_sd, theta_init):\n",
    "    theta_save = np.zeros((ntot, 9))\n",
    "    Loss_save = np.zeros(ntot)\n",
    "    accept = np.zeros(9)\n",
    "\n",
    "    theta_current = theta_init\n",
    "    theta_prop = theta_current.copy()\n",
    "\n",
    "    Loss_current = Loss(data, theta_current.tolist())\n",
    "    \n",
    "    for i in range(ntot):\n",
    "        #store current state of MCMC chain\n",
    "        theta_save[i,:] = theta_current\n",
    "        Loss_save[i] = Loss_current\n",
    "        \n",
    "        for j in range(9):\n",
    "            #draw a proposal for j-th component\n",
    "            theta_prop[j] = np.random.normal(theta_current[j], proposal_sd, size = 1)\n",
    "\n",
    "            #Loss_current = Loss(tdata, theta_current.tolist())\n",
    "            #evaluate Loss of theta proposal state\n",
    "            Loss_prop = Loss(data, theta_prop.tolist())\n",
    "            \n",
    "            #evaluate acceptance probability of proposal state\n",
    "            #NOTICE: posterior = exp(-Loss(theta))\n",
    "            #        for numerical stability in logarithm \n",
    "            alpha = np.log(np.exp(-Loss_prop)) - np.log(np.exp(-Loss_current))\n",
    "            \n",
    "            #update state with probability alpha\n",
    "            u = np.random.uniform(size = 1)\n",
    "            if alpha > np.log(u):\n",
    "                theta_current = theta_prop.copy()\n",
    "                Loss_current = Loss_prop\n",
    "                accept[j] += 1\n",
    "            else:\n",
    "                theta_prop = theta_current.copy() #proposal was declined -> reset to current state\n",
    "    \n",
    "    return [theta_save, accept, Loss_save]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06b2e2d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-63b9d7e6dc5a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0minit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnormal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m9\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mtheta_save\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mLoss_save\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrandom_walk_metropolis_hastings\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mntot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m20000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mproposal_sd\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_init\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minit\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-fe1cc3937a73>\u001b[0m in \u001b[0;36mrandom_walk_metropolis_hastings\u001b[1;34m(data, ntot, proposal_sd, theta_init)\u001b[0m\n\u001b[0;32m     20\u001b[0m             \u001b[1;31m#Loss_current = Loss(tdata, theta_current.tolist())\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[1;31m#evaluate Loss of theta proposal state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m             \u001b[0mLoss_prop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtheta_prop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[1;31m#evaluate acceptance probability of proposal state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-55aa482b44e0>\u001b[0m in \u001b[0;36mLoss\u001b[1;34m(data, theta)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 49\u001b[1;33m         \u001b[0mc_hat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mp_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0mtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mc_hat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-55aa482b44e0>\u001b[0m in \u001b[0;36mp_classifier\u001b[1;34m(x1, x2, theta)\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mu2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw21\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw22\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mb2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mz1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msig_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu1\u001b[0m\u001b[1;33m)\u001b[0m            \u001b[1;31m# hidden node outputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[0mz2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msig_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mu2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mu3\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mw31\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mz1\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mw32\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mz2\u001b[0m \u001b[1;33m+\u001b[0m\u001b[0mb3\u001b[0m    \u001b[1;31m# 2nd layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-55aa482b44e0>\u001b[0m in \u001b[0;36msig_act\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msig_act\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msig_act_prime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "init = np.random.normal(size = (9))\n",
    "theta_save, accept, Loss_save = random_walk_metropolis_hastings(data=tdata, ntot=20000, proposal_sd=1, theta_init=init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa3dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Analysis of MCMC chain\n",
    "print(f'acceptance rates: {accept/ntot}')\n",
    "print(f'min Loss: {Loss_save.min()}')\n",
    "print(f'mean Loss: {Loss_save.mean()}')\n",
    "print(f'max Loss: {Loss_save.max()}')\n",
    "print(f'std Loss: {Loss_save.std()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a3c036e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convergence diagnostics - Trace plots\n",
    "import pandas as pd\n",
    "pd.DataFrame(theta_save).plot(subplots = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd85320",
   "metadata": {},
   "outputs": [],
   "source": [
    "nburn = 5000\n",
    "n = ntot - nburn\n",
    "\n",
    "fig, axs = plt.subplots(3,3, sharey='row')\n",
    "\n",
    "for i, ax in enumerate(axs.flatten()):\n",
    "    aa1,bb1 = np.histogram(theta_save[-n:,i], bins=50,density=True)\n",
    "    \n",
    "    ax.plot(bb1[:-1],aa1)\n",
    "    ax.set_xlabel(r'$\\theta$'+f'$_{i}$')\n",
    "    #ax.set_ylabel('density')\n",
    "\n",
    "#plt.title(f\"Marginal posterior of theta[{pos}]\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
